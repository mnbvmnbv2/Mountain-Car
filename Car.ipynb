{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7764110b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\flatbuffers\\compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  'hamming': pil_image.HAMMING,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  'box': pil_image.BOX,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  'lanczos': pil_image.LANCZOS,\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593313f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of State Space ->  2\n",
      "Size of Action Space ->  1\n",
      "Max Value of Action ->  1.0\n",
      "Min Value of Action ->  -1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "problem = \"MountainCarContinuous-v0\"\n",
    "env = gym.make(problem)\n",
    "\n",
    "# This is needed to get the input size for the NN\n",
    "num_states = env.observation_space.shape[0]\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_actions = env.action_space.shape[0]\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "\n",
    "# This is needed to clip the actions within the legal boundaries\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "\n",
    "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
    "print(\"Min Value of Action ->  {}\".format(lower_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a25ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a noise used in the paper that introduced DDPG https://arxiv.org/pdf/1509.02971v6.pdf\n",
    "# From what I understand, we can also use Gaussian or other noise without much difference,\n",
    "# I left the noise as is\n",
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493ba423",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Its important to make sure we only sample from used buffer space\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "\n",
    "    # Makes a record of the outputted (s,a,r,s') obervation tuple\n",
    "    def record(self, obs_tuple):\n",
    "        # Reuse the same buffer replacing old entries\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "\n",
    "        self.buffer_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f235a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(layer1=400, layer2=300):\n",
    "    # Initialize weights between -3e-3 and 3-e3\n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_states,))\n",
    "    out = layers.Dense(layer1, activation=\"relu\")(inputs)\n",
    "    out = layers.Dense(layer2, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(1, activation=\"tanh\", kernel_initializer=last_init)(out)\n",
    "\n",
    "    # Multiply to fill the whole action space which should be equal around 0\n",
    "    outputs = outputs * upper_bound\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def get_critic(layer1=400, layer2=300):\n",
    "    # State as input\n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "\n",
    "    # Action as input\n",
    "    action_input = layers.Input(shape=(num_actions))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "\n",
    "    concat = layers.Concatenate()([state_out, action_out])\n",
    "\n",
    "    out = layers.Dense(layer1, activation=\"relu\")(concat)\n",
    "    out = layers.Dense(layer2, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "\n",
    "    # Make it into a keras model\n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c76273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object):\n",
    "    sampled_actions = tf.squeeze(actor_model(state))\n",
    "    noise = noise_object()\n",
    "    # Adding noise to action\n",
    "    sampled_actions = sampled_actions.numpy() + noise\n",
    "\n",
    "    # We make sure action is within bounds\n",
    "    legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "    return [np.squeeze(legal_action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d09a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, buffer_capacity=50000, batch_size=64, std_dev=0.2, critic_lr=0.002,\n",
    "            actor_lr=0.001, gamma=0.99, tau=0.005):\n",
    "        \n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.batch_size = batch_size\n",
    "        self.std_dev = std_dev\n",
    "        self.critic_lr = critic_lr\n",
    "        self.actor_lr = actor_lr\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.actor_model = get_actor(layer1=400, layer2=300)\n",
    "        self.critic_model = get_critic(layer1=400, layer2=300)\n",
    "\n",
    "        self.target_actor = get_actor(layer1=400, layer2=300)\n",
    "        self.target_critic = get_critic(layer1=400, layer2=300)\n",
    "        \n",
    "        self.critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "        self.actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "        \n",
    "        # Making the weights equal initially\n",
    "        self.target_actor.set_weights(self.actor_model.get_weights())\n",
    "        self.target_critic.set_weights(self.critic_model.get_weights())\n",
    "        \n",
    "        self.buffer = Buffer(buffer_capacity, batch_size)\n",
    "        \n",
    "        self.ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
    "    \n",
    "    # Move the update and learn function from buffer to Agent to \"decrease\" scope\n",
    "    @tf.function\n",
    "    def update(\n",
    "        self, state_batch, action_batch, reward_batch, next_state_batch,\n",
    "    ):\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = self.target_actor(next_state_batch, training=True)\n",
    "            y = reward_batch + self.gamma * self.target_critic(\n",
    "                [next_state_batch, target_actions], training=True\n",
    "            )\n",
    "            critic_value = self.critic_model([state_batch, action_batch], training=True)\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, self.critic_model.trainable_variables)\n",
    "        self.critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, self.critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = self.actor_model(state_batch, training=True)\n",
    "            critic_value = self.critic_model([state_batch, actions], training=True)\n",
    "\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, self.actor_model.trainable_variables)\n",
    "        self.actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, self.actor_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "    # We compute the loss and update parameters\n",
    "    def learn(self):\n",
    "        # Sample only valid data\n",
    "        record_range = min(self.buffer.buffer_counter, self.buffer_capacity)\n",
    "        # Randomly sample indices\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.buffer.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.buffer.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.buffer.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.buffer.next_state_buffer[batch_indices])\n",
    "\n",
    "        self.update(state_batch, action_batch, reward_batch, next_state_batch)\n",
    "        \n",
    "    def policy(self, state, noise_object, use_noise=True):\n",
    "        # For doing actions without added noise\n",
    "        if not use_noise:     \n",
    "            sampled_actions = tf.squeeze(actor_model(state)).numpy()\n",
    "            legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "            return [np.squeeze(legal_action)]\n",
    "        else:\n",
    "            sampled_actions = tf.squeeze(self.actor_model(state))\n",
    "            noise = noise_object()\n",
    "            # Adding noise to action\n",
    "            sampled_actions = sampled_actions.numpy() + noise\n",
    "\n",
    "            # We make sure action is within bounds\n",
    "            legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "            return [np.squeeze(legal_action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b89a8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This updates the weights in a slow manner which keeps stability\n",
    "@tf.function\n",
    "def update_target(target_weights, weights, tau):\n",
    "    for (a, b) in zip(target_weights, weights):\n",
    "        a.assign(b * tau + a * (1 - tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42f9f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(total_trials=3, total_episodes=100, use_curve=False, curve_scale=1, use_momentum=False):\n",
    "    # To store reward history of each episode\n",
    "    ep_reward_list = []\n",
    "    # To store average reward history of last few episodes\n",
    "    avg_reward_list = []\n",
    "    # To separate assisted reward structures from the \"true\"\n",
    "    true_reward_list = []\n",
    "    true_avg_reward_list = []\n",
    "    \n",
    "    for trial in range(total_trials):\n",
    "\n",
    "        # add sublists for each trial\n",
    "        avg_reward_list.append([])\n",
    "        ep_reward_list.append([])\n",
    "        \n",
    "        true_reward_list.append([])\n",
    "        true_avg_reward_list.append([])\n",
    "        \n",
    "        agent = Agent(buffer_capacity=50000, batch_size=64, std_dev=0.2, critic_lr=0.002,\n",
    "                actor_lr=0.001, gamma=0.99, tau=0.005)\n",
    "\n",
    "        for ep in range(total_episodes):\n",
    "            # Used for time benchmarking\n",
    "            before = time.time()\n",
    "\n",
    "            prev_state = env.reset()\n",
    "            episodic_reward = 0\n",
    "            true_reward = 0\n",
    "\n",
    "            while True:\n",
    "                tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "                action = agent.policy(tf_prev_state, agent.ou_noise)\n",
    "                # Recieve state and reward from environment.\n",
    "                state, reward, done, info = env.step(action)\n",
    "                \n",
    "                # Add this before eventual reward modification\n",
    "                true_reward += reward\n",
    "                \n",
    "                if use_curve:\n",
    "                    # https://medium.com/reinforcement-learning-w-policy-gradients/mountaincarcontinous-cheating-8446b09647ba\n",
    "                    # true_state = np.abs(np.cos(np.pi/3.) + state[0])\n",
    "                    # reward += -(1. - true_state)\n",
    "                    \n",
    "                    # I am a bit unsure how the curve is calculated (it just says sinusoidal on the webpage)\n",
    "                    # I base my attempt at the bottom being -0.5 and top right being 0.5\n",
    "                    # so the below code is my attempt at this type of reward\n",
    "                    reward += (np.sin(state[0] * np.pi) + 1)/curve_scale\n",
    "                    # it adds 0 at the bottom and 2 at the top of the curve\n",
    "                    # adds curve scale as the reward could be too high\n",
    "                    \n",
    "                if use_momentum:\n",
    "                    # having 0 speed and being in 0,5 (which i guess is the bottom) should incur max penalty\n",
    "                    # having max speed and beging in 0,5 should not give any penalty\n",
    "                    # the rest of the penalties should be smooth around the bottom with regards to the speed\n",
    "                    reward -= max(0, np.cos(state[1]*np.pi*10))*max(0, np.cos((state[0]+0.5)*np.pi*2))\n",
    "                    #this version gives penalty for 0.05 or lower speeds in ca. range -0.7 to -0.3\n",
    "\n",
    "                agent.buffer.record((prev_state, action, reward, state))\n",
    "                episodic_reward += reward\n",
    "\n",
    "                agent.learn()\n",
    "                update_target(agent.target_actor.variables, agent.actor_model.variables, agent.tau)\n",
    "                update_target(agent.target_critic.variables, agent.critic_model.variables, agent.tau)\n",
    "\n",
    "                # End this episode if en episode is done\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "                prev_state = state\n",
    "\n",
    "            ep_reward_list[trial].append(episodic_reward)\n",
    "            \n",
    "            true_reward_list[trial].append(true_reward)\n",
    "            \n",
    "            true_avg_reward = np.mean(true_reward_list[trial][-40:])\n",
    "            true_avg_reward_list[trial].append(true_avg_reward)\n",
    "\n",
    "            # Mean of last 40 episodes\n",
    "            avg_reward = np.mean(ep_reward_list[trial][-40:])\n",
    "            print(\"Episode * {} * Avg Reward is ==> {} * true_avg_reward: {} * time used: {}\"\n",
    "                  .format(ep, avg_reward, true_avg_reward, (time.time() - before)))\n",
    "            avg_reward_list[trial].append(avg_reward)\n",
    "\n",
    "    # Plotting graph\n",
    "    for idx, p in enumerate(true_avg_reward_list):\n",
    "        plt.plot(p, label=str(idx))\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"True Avg. Epsiodic Reward (40)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6b6307a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 0 * Avg Reward is ==> 181.568018548838 * true_avg_reward: -33.529075237328165 * time used: 14.68755578994751\n",
      "Episode * 1 * Avg Reward is ==> 330.25768983445727 * true_avg_reward: -45.96231426148524 * time used: 13.263930320739746\n",
      "Episode * 2 * Avg Reward is ==> 402.2328215810962 * true_avg_reward: -8.011901478765244 * time used: 12.340706586837769\n",
      "Episode * 3 * Avg Reward is ==> 348.21795379165945 * true_avg_reward: 16.255517530056473 * time used: 2.243436098098755\n",
      "Episode * 4 * Avg Reward is ==> 323.89163902420705 * true_avg_reward: 28.056234718559104 * time used: 3.433723211288452\n",
      "Episode * 5 * Avg Reward is ==> 296.6540851515933 * true_avg_reward: 38.38006228537777 * time used: 1.4997689723968506\n",
      "Episode * 6 * Avg Reward is ==> 289.9464516487962 * true_avg_reward: 35.79014952655701 * time used: 10.92523741722107\n",
      "Episode * 7 * Avg Reward is ==> 271.9446996835301 * true_avg_reward: 42.957523256967 * time used: 1.3322055339813232\n",
      "Episode * 8 * Avg Reward is ==> 262.2313629132275 * true_avg_reward: 47.982420430257385 * time used: 2.307527542114258\n",
      "Episode * 9 * Avg Reward is ==> 253.0882215811858 * true_avg_reward: 51.89458114861287 * time used: 2.3051116466522217\n",
      "Episode * 10 * Avg Reward is ==> 247.87441486586883 * true_avg_reward: 54.60490255617765 * time used: 3.072305917739868\n",
      "Episode * 11 * Avg Reward is ==> 263.6817823131579 * true_avg_reward: 56.23492858207927 * time used: 6.421372413635254\n",
      "Episode * 12 * Avg Reward is ==> 256.91072967464333 * true_avg_reward: 58.83736065077184 * time used: 2.0463860034942627\n",
      "Episode * 13 * Avg Reward is ==> 250.654940540543 * true_avg_reward: 60.98572025553675 * time used: 1.7885868549346924\n",
      "Episode * 14 * Avg Reward is ==> 245.24077371923707 * true_avg_reward: 62.91205853831164 * time used: 1.553201675415039\n",
      "Episode * 15 * Avg Reward is ==> 239.5294764842848 * true_avg_reward: 64.8117981277839 * time used: 1.4332301616668701\n",
      "Episode * 16 * Avg Reward is ==> 239.74431478339423 * true_avg_reward: 63.97297730563066 * time used: 8.486696481704712\n",
      "Episode * 17 * Avg Reward is ==> 236.29361620268435 * true_avg_reward: 65.51852939300396 * time used: 1.55961275100708\n",
      "Episode * 18 * Avg Reward is ==> 232.47368852568832 * true_avg_reward: 66.90128381081638 * time used: 1.3436024188995361\n",
      "Episode * 19 * Avg Reward is ==> 229.02011870018765 * true_avg_reward: 68.14682870238401 * time used: 1.3385725021362305\n",
      "Episode * 20 * Avg Reward is ==> 226.23091915236395 * true_avg_reward: 69.30333186264211 * time used: 1.3615353107452393\n",
      "Episode * 21 * Avg Reward is ==> 222.92732946348434 * true_avg_reward: 70.30742853918169 * time used: 1.2499644756317139\n",
      "Episode * 22 * Avg Reward is ==> 221.58287428726112 * true_avg_reward: 71.26658389123403 * time used: 1.4889228343963623\n",
      "Episode * 23 * Avg Reward is ==> 220.1073275841203 * true_avg_reward: 72.15265054634462 * time used: 1.466442346572876\n",
      "Episode * 24 * Avg Reward is ==> 218.44041487535043 * true_avg_reward: 73.00705770051898 * time used: 1.1994893550872803\n",
      "Episode * 25 * Avg Reward is ==> 215.85268442503653 * true_avg_reward: 73.74320918675103 * time used: 1.2729568481445312\n",
      "Episode * 26 * Avg Reward is ==> 213.83438828811964 * true_avg_reward: 74.43670213733127 * time used: 1.1701781749725342\n",
      "Episode * 27 * Avg Reward is ==> 212.10293637715088 * true_avg_reward: 75.05138032827719 * time used: 1.2792489528656006\n",
      "Episode * 28 * Avg Reward is ==> 209.96423540869733 * true_avg_reward: 75.6413886937933 * time used: 1.4446065425872803\n",
      "Episode * 29 * Avg Reward is ==> 207.89017105206705 * true_avg_reward: 76.18518719443907 * time used: 1.2531473636627197\n",
      "Episode * 30 * Avg Reward is ==> 206.3118536522168 * true_avg_reward: 76.71699560016962 * time used: 1.2366127967834473\n",
      "Episode * 31 * Avg Reward is ==> 204.77935429381412 * true_avg_reward: 77.19392998793472 * time used: 1.1593754291534424\n",
      "Episode * 32 * Avg Reward is ==> 203.53930799995393 * true_avg_reward: 77.65553819043545 * time used: 1.0338759422302246\n",
      "Episode * 33 * Avg Reward is ==> 202.63792498917874 * true_avg_reward: 78.12704513310611 * time used: 1.3663346767425537\n",
      "Episode * 34 * Avg Reward is ==> 203.3071803417729 * true_avg_reward: 78.44233915860264 * time used: 2.5125272274017334\n",
      "Episode * 35 * Avg Reward is ==> 201.959023314642 * true_avg_reward: 78.85825740034126 * time used: 1.404811143875122\n",
      "Episode * 36 * Avg Reward is ==> 201.1527906957689 * true_avg_reward: 79.24033767320344 * time used: 1.351858377456665\n",
      "Episode * 37 * Avg Reward is ==> 199.71878708286118 * true_avg_reward: 79.6048703331503 * time used: 1.169825792312622\n",
      "Episode * 38 * Avg Reward is ==> 198.97974157258207 * true_avg_reward: 79.94159279071518 * time used: 1.1672987937927246\n",
      "Episode * 39 * Avg Reward is ==> 198.23964446573763 * true_avg_reward: 80.29140459271454 * time used: 1.199519157409668\n",
      "Episode * 40 * Avg Reward is ==> 197.73026343089725 * true_avg_reward: 83.47834246132444 * time used: 1.2363755702972412\n",
      "Episode * 41 * Avg Reward is ==> 189.60155769096298 * true_avg_reward: 87.27707015323601 * time used: 1.3013944625854492\n",
      "Episode * 42 * Avg Reward is ==> 179.99934336019876 * true_avg_reward: 87.87543728667693 * time used: 1.0789687633514404\n",
      "Episode * 43 * Avg Reward is ==> 178.7037433603659 * true_avg_reward: 87.98009987167765 * time used: 0.8656277656555176\n",
      "Episode * 44 * Avg Reward is ==> 176.46478482399894 * true_avg_reward: 88.42246409177065 * time used: 1.0303871631622314\n",
      "Episode * 45 * Avg Reward is ==> 175.88579114766281 * true_avg_reward: 88.5175506311342 * time used: 1.1330292224884033\n",
      "Episode * 46 * Avg Reward is ==> 172.95682738708612 * true_avg_reward: 90.36707104735646 * time used: 0.8906557559967041\n",
      "Episode * 47 * Avg Reward is ==> 172.75392648546804 * true_avg_reward: 90.3733506424679 * time used: 1.0890517234802246\n",
      "Episode * 48 * Avg Reward is ==> 171.4359620888394 * true_avg_reward: 90.52014660493151 * time used: 1.101400375366211\n",
      "Episode * 49 * Avg Reward is ==> 170.46892168328947 * true_avg_reward: 90.68730399644836 * time used: 1.1270983219146729\n",
      "Episode * 50 * Avg Reward is ==> 168.92542313526934 * true_avg_reward: 90.9975677313599 * time used: 1.0758657455444336\n",
      "Episode * 51 * Avg Reward is ==> 161.42630874651167 * true_avg_reward: 91.49739590776572 * time used: 1.2269728183746338\n",
      "Episode * 52 * Avg Reward is ==> 160.41919630207377 * true_avg_reward: 91.5983344797914 * time used: 1.0395474433898926\n",
      "Episode * 53 * Avg Reward is ==> 159.53497064946288 * true_avg_reward: 91.71181986130304 * time used: 1.1033382415771484\n",
      "Episode * 54 * Avg Reward is ==> 159.49784835403173 * true_avg_reward: 91.69639838566236 * time used: 1.9319438934326172\n",
      "Episode * 55 * Avg Reward is ==> 158.91330179252762 * true_avg_reward: 91.69516791243043 * time used: 1.1206269264221191\n",
      "Episode * 56 * Avg Reward is ==> 156.1522460640102 * true_avg_reward: 92.77804453549801 * time used: 0.9570176601409912\n",
      "Episode * 57 * Avg Reward is ==> 155.1541031012163 * true_avg_reward: 92.83273938868459 * time used: 0.9448807239532471\n",
      "Episode * 58 * Avg Reward is ==> 154.34478087112817 * true_avg_reward: 92.87402988873818 * time used: 0.9184350967407227\n",
      "Episode * 59 * Avg Reward is ==> 154.38011879959123 * true_avg_reward: 92.81451230179114 * time used: 1.5778989791870117\n",
      "Episode * 60 * Avg Reward is ==> 153.50265894555602 * true_avg_reward: 92.83261821702227 * time used: 0.9536974430084229\n",
      "Episode * 61 * Avg Reward is ==> 153.03791772426513 * true_avg_reward: 92.8889450340849 * time used: 0.8758032321929932\n",
      "Episode * 62 * Avg Reward is ==> 151.54229501948262 * true_avg_reward: 92.93321254125591 * time used: 0.8350870609283447\n",
      "Episode * 63 * Avg Reward is ==> 150.15292005783087 * true_avg_reward: 92.97597860697881 * time used: 0.8593747615814209\n",
      "Episode * 64 * Avg Reward is ==> 150.20013238530743 * true_avg_reward: 92.85979740934457 * time used: 1.8668076992034912\n",
      "Episode * 65 * Avg Reward is ==> 149.8819148976667 * true_avg_reward: 92.90240989734502 * time used: 1.2251369953155518\n",
      "Episode * 66 * Avg Reward is ==> 149.08825449081547 * true_avg_reward: 92.95121773430607 * time used: 1.0369281768798828\n",
      "Episode * 67 * Avg Reward is ==> 148.48806998531828 * true_avg_reward: 93.02444593986397 * time used: 1.176863431930542\n",
      "Episode * 68 * Avg Reward is ==> 147.95674722580938 * true_avg_reward: 93.06128984505588 * time used: 1.1374640464782715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 69 * Avg Reward is ==> 147.6535494825455 * true_avg_reward: 93.10049331051206 * time used: 0.9742105007171631\n",
      "Episode * 70 * Avg Reward is ==> 146.9376454566369 * true_avg_reward: 93.12586843873684 * time used: 0.8882861137390137\n",
      "Episode * 71 * Avg Reward is ==> 147.50822471343147 * true_avg_reward: 93.02543385225775 * time used: 1.6178147792816162\n",
      "Episode * 72 * Avg Reward is ==> 146.6328402633463 * true_avg_reward: 93.05646319716978 * time used: 0.8503775596618652\n",
      "Episode * 73 * Avg Reward is ==> 146.26485179091137 * true_avg_reward: 92.97474084775817 * time used: 1.30018949508667\n",
      "Episode * 74 * Avg Reward is ==> 144.81045354368536 * true_avg_reward: 92.9647618344864 * time used: 1.439666509628296\n",
      "Episode * 75 * Avg Reward is ==> 145.1069531403783 * true_avg_reward: 92.87359886789409 * time used: 1.6731688976287842\n",
      "Episode * 76 * Avg Reward is ==> 144.84943075512655 * true_avg_reward: 92.893401624598 * time used: 1.8267395496368408\n",
      "Episode * 77 * Avg Reward is ==> 146.48192381485387 * true_avg_reward: 92.90293213271535 * time used: 2.5369606018066406\n",
      "Episode * 78 * Avg Reward is ==> 148.617084978542 * true_avg_reward: 92.89786406095166 * time used: 5.405238151550293\n",
      "Episode * 79 * Avg Reward is ==> 149.26968743219126 * true_avg_reward: 92.87218137774468 * time used: 2.0450828075408936\n",
      "Episode * 80 * Avg Reward is ==> 150.50414299544084 * true_avg_reward: 92.80565988305345 * time used: 2.037198781967163\n",
      "Episode * 81 * Avg Reward is ==> 149.94832341609734 * true_avg_reward: 92.81903402472716 * time used: 0.9570729732513428\n",
      "Episode * 82 * Avg Reward is ==> 150.510341844725 * true_avg_reward: 92.78425639274315 * time used: 1.467381477355957\n",
      "Episode * 83 * Avg Reward is ==> 152.62006108105783 * true_avg_reward: 92.59890740762452 * time used: 2.883049726486206\n",
      "Episode * 84 * Avg Reward is ==> 154.23121272988425 * true_avg_reward: 92.44245836867341 * time used: 2.7272796630859375\n",
      "Episode * 85 * Avg Reward is ==> 155.49419353477933 * true_avg_reward: 92.30935150601118 * time used: 1.5497024059295654\n",
      "Episode * 86 * Avg Reward is ==> 155.85262066064166 * true_avg_reward: 92.28546552534243 * time used: 0.9507191181182861\n",
      "Episode * 87 * Avg Reward is ==> 156.1529878663987 * true_avg_reward: 92.28387468553517 * time used: 1.0189414024353027\n",
      "Episode * 88 * Avg Reward is ==> 157.28751549235838 * true_avg_reward: 92.24795329738402 * time used: 1.6115405559539795\n",
      "Episode * 89 * Avg Reward is ==> 158.4305030738215 * true_avg_reward: 92.24008539783426 * time used: 1.892749309539795\n",
      "Episode * 90 * Avg Reward is ==> 165.7880457303255 * true_avg_reward: 92.03374115974978 * time used: 5.714660406112671\n",
      "Episode * 91 * Avg Reward is ==> 166.81567932292288 * true_avg_reward: 92.00950766733627 * time used: 2.1638219356536865\n",
      "Episode * 92 * Avg Reward is ==> 167.0094659037318 * true_avg_reward: 92.03994894648079 * time used: 1.2265326976776123\n",
      "Episode * 93 * Avg Reward is ==> 167.35847377214682 * true_avg_reward: 92.09620851521836 * time used: 0.967320442199707\n",
      "Episode * 94 * Avg Reward is ==> 168.1335744349632 * true_avg_reward: 92.18922814697729 * time used: 1.954042673110962\n",
      "Episode * 95 * Avg Reward is ==> 169.36336570816016 * true_avg_reward: 92.19961042862032 * time used: 1.885993480682373\n",
      "Episode * 96 * Avg Reward is ==> 169.59600636592927 * true_avg_reward: 92.2384345165381 * time used: 0.8517670631408691\n",
      "Episode * 97 * Avg Reward is ==> 169.9395797435408 * true_avg_reward: 92.24709314131971 * time used: 1.0576019287109375\n",
      "Episode * 98 * Avg Reward is ==> 171.11223903983696 * true_avg_reward: 92.20864205594899 * time used: 1.989353895187378\n",
      "Episode * 99 * Avg Reward is ==> 170.78023540931886 * true_avg_reward: 92.36541064220572 * time used: 1.2496113777160645\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run(total_trials=1, total_episodes=100, use_curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2319f6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 0 * Avg Reward is ==> -617.3922075847994 * true_avg_reward: -51.16369704999744 * time used: 15.569496154785156\n",
      "Episode * 1 * Avg Reward is ==> -546.8117628162248 * true_avg_reward: -44.24461935430679 * time used: 13.874409198760986\n",
      "Episode * 2 * Avg Reward is ==> -399.96514539842616 * true_avg_reward: -10.79462063178491 * time used: 11.540255069732666\n",
      "Episode * 3 * Avg Reward is ==> -289.05285025779597 * true_avg_reward: 12.529993525988294 * time used: 3.46454119682312\n",
      "Episode * 4 * Avg Reward is ==> -333.28269929402114 * true_avg_reward: -8.259079757337794 * time used: 14.653981685638428\n",
      "Episode * 5 * Avg Reward is ==> -267.6027726945269 * true_avg_reward: 7.89334769039798 * time used: 2.136054515838623\n",
      "Episode * 6 * Avg Reward is ==> -219.1064091048054 * true_avg_reward: 19.524450864915973 * time used: 1.9926142692565918\n",
      "Episode * 7 * Avg Reward is ==> -183.45829929438156 * true_avg_reward: 28.23044186349318 * time used: 2.0895864963531494\n",
      "Episode * 8 * Avg Reward is ==> -155.8709561765977 * true_avg_reward: 35.039678897925945 * time used: 1.8964414596557617\n",
      "Episode * 9 * Avg Reward is ==> -136.07004121766278 * true_avg_reward: 40.771772493340805 * time used: 1.6114368438720703\n",
      "Episode * 10 * Avg Reward is ==> -117.47583002327683 * true_avg_reward: 45.24364792874882 * time used: 1.917593240737915\n",
      "Episode * 11 * Avg Reward is ==> -103.04590132638539 * true_avg_reward: 48.853198848363604 * time used: 2.2194764614105225\n",
      "Episode * 12 * Avg Reward is ==> -90.30690212240425 * true_avg_reward: 52.34878615262642 * time used: 1.297961950302124\n",
      "Episode * 13 * Avg Reward is ==> -79.86880965978223 * true_avg_reward: 55.29312240563221 * time used: 1.2723419666290283\n",
      "Episode * 14 * Avg Reward is ==> -70.03922765086769 * true_avg_reward: 57.55986100495831 * time used: 1.999183177947998\n",
      "Episode * 15 * Avg Reward is ==> -61.21122026419811 * true_avg_reward: 59.87207593038967 * time used: 1.2344310283660889\n",
      "Episode * 16 * Avg Reward is ==> -53.64259687997302 * true_avg_reward: 61.64435332006907 * time used: 1.954026460647583\n",
      "Episode * 17 * Avg Reward is ==> -46.55791892566873 * true_avg_reward: 63.17838452357877 * time used: 1.9594295024871826\n",
      "Episode * 18 * Avg Reward is ==> -40.21147078024727 * true_avg_reward: 64.76239532373904 * time used: 1.1906273365020752\n",
      "Episode * 19 * Avg Reward is ==> -34.77739265771856 * true_avg_reward: 65.90585096428512 * time used: 2.0275747776031494\n",
      "Episode * 20 * Avg Reward is ==> -33.10314179513695 * true_avg_reward: 66.36287850388771 * time used: 4.148752927780151\n",
      "Episode * 21 * Avg Reward is ==> -28.62958282479186 * true_avg_reward: 67.48468622814106 * time used: 1.5064213275909424\n",
      "Episode * 22 * Avg Reward is ==> -24.161115144515044 * true_avg_reward: 68.43850010399856 * time used: 1.6841375827789307\n",
      "Episode * 23 * Avg Reward is ==> -35.694396885215 * true_avg_reward: 67.52370451796365 * time used: 12.228663444519043\n",
      "Episode * 24 * Avg Reward is ==> -31.378269255476944 * true_avg_reward: 68.49738765538623 * time used: 1.6055331230163574\n",
      "Episode * 25 * Avg Reward is ==> -27.4675773439891 * true_avg_reward: 69.4650700498105 * time used: 1.578336477279663\n",
      "Episode * 26 * Avg Reward is ==> -24.791958707151913 * true_avg_reward: 70.42675982360149 * time used: 1.7274627685546875\n",
      "Episode * 27 * Avg Reward is ==> -21.57009567453008 * true_avg_reward: 71.29690301565871 * time used: 1.7365987300872803\n",
      "Episode * 28 * Avg Reward is ==> -18.518470233698594 * true_avg_reward: 72.10593044671883 * time used: 1.8669991493225098\n",
      "Episode * 29 * Avg Reward is ==> -16.061448466304185 * true_avg_reward: 72.87241743855414 * time used: 1.8163652420043945\n",
      "Episode * 30 * Avg Reward is ==> -15.49770055215392 * true_avg_reward: 73.59728480444586 * time used: 2.56612229347229\n",
      "Episode * 31 * Avg Reward is ==> -12.991145721654743 * true_avg_reward: 74.26759998793051 * time used: 1.9282827377319336\n",
      "Episode * 32 * Avg Reward is ==> -11.16396454926204 * true_avg_reward: 74.95672399566506 * time used: 2.2651238441467285\n",
      "Episode * 33 * Avg Reward is ==> -9.412305528683198 * true_avg_reward: 75.52897113746062 * time used: 1.7628142833709717\n",
      "Episode * 34 * Avg Reward is ==> -7.426211577075482 * true_avg_reward: 75.93078197315647 * time used: 1.864013910293579\n",
      "Episode * 35 * Avg Reward is ==> -6.040956755265578 * true_avg_reward: 76.32635148020128 * time used: 2.0103306770324707\n",
      "Episode * 36 * Avg Reward is ==> -5.493156012657161 * true_avg_reward: 76.71021892811928 * time used: 2.6067893505096436\n",
      "Episode * 37 * Avg Reward is ==> -3.3714097250975663 * true_avg_reward: 77.07009837418495 * time used: 1.6778781414031982\n",
      "Episode * 38 * Avg Reward is ==> -2.189382663519998 * true_avg_reward: 77.44230338382485 * time used: 2.2790491580963135\n",
      "Episode * 39 * Avg Reward is ==> -1.5613344945516894 * true_avg_reward: 77.86255674706335 * time used: 2.3944685459136963\n",
      "Episode * 40 * Avg Reward is ==> 14.543841038191156 * true_avg_reward: 81.55267623215256 * time used: 2.1462080478668213\n",
      "Episode * 41 * Avg Reward is ==> 27.549496315269153 * true_avg_reward: 84.87837170787743 * time used: 1.6632544994354248\n",
      "Episode * 42 * Avg Reward is ==> 30.71025874339485 * true_avg_reward: 85.759114775091 * time used: 2.6531875133514404\n",
      "Episode * 43 * Avg Reward is ==> 30.329905051660575 * true_avg_reward: 86.05876980757994 * time used: 1.8817706108093262\n",
      "Episode * 44 * Avg Reward is ==> 44.42438648009348 * true_avg_reward: 90.69470976255455 * time used: 1.2548017501831055\n",
      "Episode * 45 * Avg Reward is ==> 44.443255391161756 * true_avg_reward: 90.76901163984408 * time used: 1.5955054759979248\n",
      "Episode * 46 * Avg Reward is ==> 43.6932307026302 * true_avg_reward: 90.78175746376205 * time used: 2.2699968814849854\n",
      "Episode * 47 * Avg Reward is ==> 43.88509882478992 * true_avg_reward: 90.77669607306515 * time used: 1.7489128112792969\n",
      "Episode * 48 * Avg Reward is ==> 44.12431257696507 * true_avg_reward: 90.77468715297192 * time used: 1.8048367500305176\n",
      "Episode * 49 * Avg Reward is ==> 44.764727013577556 * true_avg_reward: 90.71764163517601 * time used: 1.8223388195037842\n",
      "Episode * 50 * Avg Reward is ==> 44.84198137843332 * true_avg_reward: 90.71255049242592 * time used: 1.6971492767333984\n",
      "Episode * 51 * Avg Reward is ==> 45.29845680553594 * true_avg_reward: 90.72069097053337 * time used: 1.7109317779541016\n",
      "Episode * 52 * Avg Reward is ==> 45.531899805959554 * true_avg_reward: 90.59377086347129 * time used: 1.7876996994018555\n",
      "Episode * 53 * Avg Reward is ==> 45.99878728810518 * true_avg_reward: 90.61607753813875 * time used: 1.0812242031097412\n",
      "Episode * 54 * Avg Reward is ==> 45.924277959213654 * true_avg_reward: 90.65001426701488 * time used: 1.8761556148529053\n",
      "Episode * 55 * Avg Reward is ==> 45.97791151272352 * true_avg_reward: 90.51094911039434 * time used: 1.9904358386993408\n",
      "Episode * 56 * Avg Reward is ==> 46.07463314420956 * true_avg_reward: 90.5295977451899 * time used: 1.6617639064788818\n",
      "Episode * 57 * Avg Reward is ==> 45.77011302236328 * true_avg_reward: 90.64915220233578 * time used: 1.136603593826294\n",
      "Episode * 58 * Avg Reward is ==> 45.678963811213706 * true_avg_reward: 90.5401453873601 * time used: 1.7673454284667969\n",
      "Episode * 59 * Avg Reward is ==> 45.182567754569575 * true_avg_reward: 90.54688233975256 * time used: 2.4184658527374268\n",
      "Episode * 60 * Avg Reward is ==> 46.904615928307166 * true_avg_reward: 91.02193745409461 * time used: 0.9964022636413574\n",
      "Episode * 61 * Avg Reward is ==> 46.68733657165644 * true_avg_reward: 91.07751027976538 * time used: 1.1817243099212646\n",
      "Episode * 62 * Avg Reward is ==> 46.56346676627694 * true_avg_reward: 91.20687561493784 * time used: 1.170576572418213\n",
      "Episode * 63 * Avg Reward is ==> 54.93587385811618 * true_avg_reward: 92.28998666486103 * time used: 1.7982678413391113\n",
      "Episode * 64 * Avg Reward is ==> 54.97362946379678 * true_avg_reward: 92.31676847583117 * time used: 1.6655657291412354\n",
      "Episode * 65 * Avg Reward is ==> 55.12029686163312 * true_avg_reward: 92.33366609970807 * time used: 0.9604933261871338\n",
      "Episode * 66 * Avg Reward is ==> 55.65906429686429 * true_avg_reward: 92.30493400014646 * time used: 1.1417808532714844\n",
      "Episode * 67 * Avg Reward is ==> 55.94332883889149 * true_avg_reward: 92.24775770541449 * time used: 1.529991865158081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 68 * Avg Reward is ==> 56.03941436248675 * true_avg_reward: 92.16345985267144 * time used: 1.8459861278533936\n",
      "Episode * 69 * Avg Reward is ==> 56.41320804435627 * true_avg_reward: 92.16114476176595 * time used: 1.0832555294036865\n",
      "Episode * 70 * Avg Reward is ==> 58.244413572378065 * true_avg_reward: 92.11652544426359 * time used: 2.0765745639801025\n",
      "Episode * 71 * Avg Reward is ==> 57.718333527558926 * true_avg_reward: 92.04515821573708 * time used: 3.223470687866211\n",
      "Episode * 72 * Avg Reward is ==> 58.4249983125442 * true_avg_reward: 92.01403242028535 * time used: 1.0651042461395264\n",
      "Episode * 73 * Avg Reward is ==> 59.00207277879046 * true_avg_reward: 91.99910055231841 * time used: 1.9062201976776123\n",
      "Episode * 74 * Avg Reward is ==> 59.31863928327302 * true_avg_reward: 92.13788529737994 * time used: 1.6134393215179443\n",
      "Episode * 75 * Avg Reward is ==> 59.85240874378398 * true_avg_reward: 92.25775191225674 * time used: 1.7220447063446045\n",
      "Episode * 76 * Avg Reward is ==> 61.33558034625423 * true_avg_reward: 92.33866560566541 * time used: 1.6807260513305664\n",
      "Episode * 77 * Avg Reward is ==> 60.79232957754846 * true_avg_reward: 92.43346365482067 * time used: 1.5908443927764893\n",
      "Episode * 78 * Avg Reward is ==> 61.40270312708336 * true_avg_reward: 92.48008652299286 * time used: 1.0149872303009033\n",
      "Episode * 79 * Avg Reward is ==> 62.66874448162648 * true_avg_reward: 92.3853474490027 * time used: 1.5803263187408447\n",
      "Episode * 80 * Avg Reward is ==> 63.862870232874364 * true_avg_reward: 92.20095749327986 * time used: 1.8028409481048584\n",
      "Episode * 81 * Avg Reward is ==> 64.51916437017408 * true_avg_reward: 92.08412191786923 * time used: 1.4903662204742432\n",
      "Episode * 82 * Avg Reward is ==> 65.86357346713064 * true_avg_reward: 92.05609218159745 * time used: 1.685950517654419\n",
      "Episode * 83 * Avg Reward is ==> 66.85716759063527 * true_avg_reward: 91.97537030389965 * time used: 1.638444423675537\n",
      "Episode * 84 * Avg Reward is ==> 67.17993846230505 * true_avg_reward: 91.89930922709387 * time used: 1.7117087841033936\n",
      "Episode * 85 * Avg Reward is ==> 67.00898445099304 * true_avg_reward: 91.74833825869844 * time used: 2.472547769546509\n",
      "Episode * 86 * Avg Reward is ==> 67.75320822783462 * true_avg_reward: 91.74520123626917 * time used: 1.6058077812194824\n",
      "Episode * 87 * Avg Reward is ==> 67.76971672365522 * true_avg_reward: 91.74050175307623 * time used: 1.6343462467193604\n",
      "Episode * 88 * Avg Reward is ==> 67.83001061879611 * true_avg_reward: 91.80413329782573 * time used: 1.5912611484527588\n",
      "Episode * 89 * Avg Reward is ==> 67.69762485091162 * true_avg_reward: 91.88361100732163 * time used: 1.5532751083374023\n",
      "Episode * 90 * Avg Reward is ==> 67.69470407580661 * true_avg_reward: 91.89189463577654 * time used: 1.4667959213256836\n",
      "Episode * 91 * Avg Reward is ==> 67.67950311569086 * true_avg_reward: 91.90704412250156 * time used: 1.7531344890594482\n",
      "Episode * 92 * Avg Reward is ==> 67.71262204794911 * true_avg_reward: 91.92960491485016 * time used: 1.7129414081573486\n",
      "Episode * 93 * Avg Reward is ==> 67.75066003583606 * true_avg_reward: 91.92310770885193 * time used: 1.0568912029266357\n",
      "Episode * 94 * Avg Reward is ==> 67.53456987455817 * true_avg_reward: 91.86981993009974 * time used: 2.3646979331970215\n",
      "Episode * 95 * Avg Reward is ==> 67.39408921119049 * true_avg_reward: 91.86561791826148 * time used: 1.8787634372711182\n",
      "Episode * 96 * Avg Reward is ==> 67.38133772989674 * true_avg_reward: 91.96327042446605 * time used: 1.1956796646118164\n",
      "Episode * 97 * Avg Reward is ==> 67.72377185536912 * true_avg_reward: 91.97632480590619 * time used: 1.0209629535675049\n",
      "Episode * 98 * Avg Reward is ==> 67.76923581475346 * true_avg_reward: 92.10431416811005 * time used: 0.9825727939605713\n",
      "Episode * 99 * Avg Reward is ==> 68.08004275222136 * true_avg_reward: 92.25747746640313 * time used: 1.2018895149230957\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run(total_trials=1, total_episodes=100, use_momentum=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3996ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest is previous code used to load weights and render. Can be reimplemented in next version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb550c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_model = get_actor()\n",
    "# actor_model.load_weights(\"/Users/Ferdi/My Drive/ColabNotebooks/Weights/car_actor.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a75429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prev_state = env.reset()\n",
    "# while True:\n",
    "#     env.render()\n",
    "\n",
    "#     tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "#     action = policy(tf_prev_state, ou_noise)\n",
    "#     state, _, done, _ = env.step(action)\n",
    "\n",
    "#     if done:\n",
    "#         break\n",
    "\n",
    "#     prev_state = state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
